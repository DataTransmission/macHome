
\begin{itemize}
    \item
    Suppose $X_{s}(t)$ and $X_{p}(t)$ are the nonlinear states generated by the stochastic parameterization and
    perturbed parameter scheme, respectively.

    Prove that $D_{\text{KL}}(p(X_{s}),p(X_{p})) < \delta$ ($\delta$ is a small number) when
    $p(e_{s}) = p(e_{p})$ is enforced regardless/independent of time.
    The difference is $e_{s}$ is sampled at each time step, and $e_{p}$ is sampled at the first time
    step and fixed throughout the integration.

    The multiplicative noise $U = (1+100^{e_{s}})\bar{U}$ can be substituted as $U = (1+100^{e_{p}})\bar{U}$.

    $e_{s} = \log_{100}(U-\bar{U}) - \log_{100}(\bar{U})$
   
    \item Hidden Markov Chain
    Divide the subgrid variable as a function of state, $U_p(\vec{X})$, graph space into hypercubes.
    Start using Hidden Markov chain to march probabilistically in this grid.

    \item Neural Network
    1. Find the functional (e.g.,PCE?) dependence jumping from one function to the other to the final state
    2. Topological path from one input to the output, using some kind of cost function to allow error tolerance?

    \item Slow and Fast stochastic process (with hidden Markov Chain). 
    1. decompose modes based on time-scale

    \item Learning Dynamical Systems (http://cs.brown.edu/research/ai/dynamics/tutorial/Documents/LearningDynamicalSystems.html)


