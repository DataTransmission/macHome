	
%		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%	
%		\subsection{Perturbed Parameter} 
%		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%	
		A perturbed parameter scheme treats $r^k$ as a time-invariant
		uncertain variable $e_s$ (a fixed value during model integration),
		\begin{equation} \label{perturbedParm}
			U_p = \bar{U} + e_s,			
		\end{equation}
		where the $k^{\text{th}}$ time index is dropped and replaced with
		the subscript $s$ representing ``stationarity".\
		The $e_s$ is a time-fixed perturbation on the regression parameter $\beta_0$ 
		(i.e., any perturbation to $\beta_0$ gives a constant 
		shift to $\bar{U}(X_1)$ along the $U$-axis).\
		Figure {\ref{blackPertCurve}} is the same as Figure {\ref{linearCurve}} (a) and (b), 
		where the black curves covering the cloud of true $\bold{U^*}$ (grey circles) show $\bar{U}$ perturbed by different values of $e_s$.\ 
		This allows us to control directly the distribution of $U_p(e_s)$ by assigning different distributions to $e_s$.
		A proper distribution of $U_p$ has the potential to capture the 
		true distribution of $\bold{U^*}$ and eventually impact the ensemble forecast skill
		(i.e., $X$'s and $Y$'s are both functions of $U_p$).\
		Therefore, this single perturbed parameter $e_s$ is used 
		in the proposed scheme (in contrast to using 
		all four parameters/regression coefficients in \citet{Arnold13}).\
		We designed both ``informative" and ``uninformative" 
		input distributions in Subsection \ref{subsec:dist_es}
		to emphasize the importance of reliable $e_s$ distributions.\
		In order to lower the cost when integrating over a large number of perturbed $e_s$,
		we build an emulator using a PCE, an analytical function of $e_s$.\ 
		The PCE-based surrogate is easy to evaluate and allows
		one to generate large ensemble states (e.g., $> 10^4$ ensemble members)
		without the need to integrate the actual model.\
		The PCE was initially developed by  {\citet{Wiener38}} 
		to address problems in statistical mechanics;
		it was applied in engineering mechanics to quantify
		uncertainties in stochastic Gaussian processes
		by {\citet{Ghanem90}}, and generalized to a wider range of stochastic processes by {\citet{Xiu02}}.

 

		
		
		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		\subsection{ PCE of a Perturbed State Variable} 
		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%	
		PCEs express the dependence of the model output variables
		on the input perturbation $e_s$ as a
		spectral series of the form {\citep{Maitre10}}:
		\begin{equation} \label{pce_compact}
			f(t,e_s) = \sum\limits_{ i=0 }^N \hat{f}_i(t)  P_i(\xi).
		\end{equation}
		where $f(t,e_s)$ is a model output variable (e.g., $X_1(t,e_s)$; separate independent PCEs can be
                constructed for any output quantity of interest),
		$\hat{f}_i(t)$ are the series coefficients,
		$P_i(\xi)$ are polynomial basis functions, 
                 $\xi$ is a standardized variable that maps the standard domain $-1\le\xi\le 1$ to the
		perturbation domain $r_{\min}\le e_s\le r_{\max}$
		\footnote{A linear mapping of the form $e_s = (r_{\max}-r_{\min}) \frac{\xi + 1}{2}+r_{\min}$ is sufficient. Here 
			$r_{\min}= \min_k r^k$ and $r_{\max} = \max_k r^k$ are the extrema of the true residual (equation \ref{true_U}).}.
		PCEs can be viewed as Fourier-like expansions in 
		the perturbed parameter and thus inherit their approximation properties; in particular PCEs
                converge spectrally fast when $f(t,e_s)$ varies smoothly with $e_s$.
		We suppress the time dependence of $f$ and $\hat{f}_i$ from now on to simplify notation.

			The basis functions are polynomials that
			are orthogonal with respect to an inner product defined by
			\begin{equation} \label{orthogonality}
				 \big< P_i,  P_j \big> 
				 = \int P_i(\xi) 
				 	P_j({\xi}) p(\xi) d\xi 
				 = \delta_{ij} \big< P_i^2 \big>
			\end{equation}
			where $\delta_{ij} = 1$ if $j=i$ and zero otherwise, and where $p(\xi)$ is a weight
			function\footnote{When the weight function coincides with the probability 
			distribution of $e_s$ the inner product can be interpreted as an expectation estimate of 
			$P_i P_j$; it is easy to show that the mean of $f$ w.r.t. $\xi$ is then simply the zeroth coefficient 
                        $\hat{f}_0$.}.
			This study uses Legendre polynomials for $P_i$, which are orthogonal 
			with respect to the uniformly distributed $\xi$ in the standardized domain $[-1 \ 1]$, 
			hence $p(\xi)=1/2$ is just constant over the domain.\
			The assumption of a uniformly distributed $\xi$ is not restrictive since, once the
			series coefficients are known, one could simply sample it with any 
			probability distribution desired.\ 
			A carefully selected distribution of $e_s$ will guarantee reliable forecasts
			since the sampling of $e_s$ affects directly the ensemble forecast state distributions.\
			This will be discussed in Subsection \ref{subsec:dist_es}.
			
			\emph{Spectral projection} can be used to obtain the coefficients $\hat{f}_{i}$, i.e.,
			one takes the inner product of equation \eqref{pce_compact} with each of the basis functions
			$P_j$ and invokes orthogonality to obtain: 
			\begin{equation} \label{PCoeff}
				\begin{aligned}
					\left< f, P_j \right>
						= \left<  \sum\limits_{i=0}^{N}
							\hat{f}_i P_i, P_j \right>
						= \hat{f}_i \left< P_i^2 \right>,
				\end{aligned}
			\mbox{ or }
				\hat{f}_i = \frac{\left< f, P_i \right>}
					{\left< P_i^2 \right>}.
			\end{equation}
			Since $f$ is not an analytical function, we use quadrature 
			(i.e., numerical integration) to approximate the numerator in \eqref{PCoeff}:
			\begin{equation}	\label{1DQ}
				\left< f, P_i \right> = \int_{-1}^1 f P_i p(\xi) d\xi \approx 
				\sum\limits_{q = 1}^{n} w_q f(t,\xi_q) P_i(\xi_q)
			\end{equation}
			$\xi_q$ are the quadrature points,
			and $w_q$ are the associated quadrature weights
			\footnote{ We have employed 
			Clenshaw-Curtis nested quadrature rule {\citep{Clenshaw60}} whose accuracy can be
			improved by increasing the number of quadrature points $n$; an $n$ point Clenshaw-Curtis quadrature would be
			exact if $(fP_ip)$ is a polynomial of degree $(n-1)$. }.
                        The evaluation of the series coefficients requires thus an ensemble of model runs to obtain
			$f(\xi_q)$ (the ensemble members correspond to setting the perturbed parameter to its value at the quadrature
			point and running the model); no code modification is needed.
			The black lines in Figure {\ref{blackPertCurve}} show 
			$U_p$ evaluated at the quadrature points, namely $e_s(\xi_q)$. 
			Equation \eqref{PCoeff} becomes
			\begin{equation} \label{PCoeff_num}
				\hat{f}_i = \frac{\sum_{i=1}^n  P_i(\xi_q) w_q f(\xi_q)}
					{\left< P_i^2 \right>}.\
			\end{equation}		
			The combination of equations \eqref{PCoeff_num} and \eqref{pce_compact}
			completes the PCE surrogate model for the perturbed forecast state variable.\
			

			As mentioned earlier, $\tau_z=2$ may be closer to a real
			atmosphere-ocean coupled system, and the atmospheric variables exhibit a relatively smooth
			variations with $e_s$. A relatively short spectral series is then expected to represent
			accurately this dependency. 
			The $\tau=10$ experiment, on the
			other hand, exhibits large jump discontinuities (and ensuing Gibbs oscillations) 
			whose number increases with longer lead time ($\ge 10$MTU).
			The discontinuities hinder the convergence rate of the PCE and a longer series is
			then needed to represent the functional relationship between the state variables and the perturbation parameter.
			The $\tau=10$ experiment required a $64^{\text{th}}$ degree polynomial and hence an ensemble size of $129$ is needed for the 
			quadrature. We use a similar sized ensemble for the $\tau=2$ experiment even though a $16^{\text{th}}$ degree polynomial
			(and $33$ ensemble members) would have been sufficient.
			The observed jump phenomena will be discussed in Subsection \ref{subsec:num_cons}.\
%			\footnote{ $33$ ($129$) quadrature points correspond to using $6^{th}$ ($8^{th}$) 
%			level Clenshaw-Curtis quadrature rule.\ }
%			Runge's phenomenon could be 
%			alleviated by dividing the uncertainty domain into local PCE 
%			approximation of piece-wise continuous function 
%			using less model runs and more accurately capturing the solution {\citep{Wan05}}.\
%			(with $8-th$ level Clenshaw-Curtis quadrature rule)
			
			Once built, PCE of a forecast state variable allows one to test any distribution of 
			$e_s$ without actually integrating the model.\
%			(other than the simulations on the quadrature points required to build the PC coefficients).\
			The perturbed parameter scheme is thus performed by sampling 
			the $e_s$ from the PCE with a proper distribution to give 
			an ensemble state distribution that generates reliable forecast.\ 


		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%			
		\subsection{Distributions of $e_s$} \label{subsec:dist_es}
		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
			In this study, $e_s$ is defined to be ``informative" when the samples 
			contain the true residuals $r^k$, and ``uninformative" when they are sampled from an 
			arbitrarily assigned distribution.

			In this study we assigned three distributions to $e_s$:
			$e_{\text{unif}}$, $e_{\text{clim}}$ and $e_{\text{AR1}}$.\
			The $e_{\text{unif}}$ distribution is uninformative and its samples are randomly 
			generated from a uniform distribution,
			whereas $e_{\text{clim}}$ and $e_{\text{AR1}}$ contain informative samples of $r^k$.\
			The $e_{\text{clim}}$ distribution was designed 
			to verify the existence of a single climatological distribution of $e_s$ for all forecast events; $e_{\text{clim}}$ is
			expected to be the most informative
			since it is based on the entire time series (1,600 MTU) of true $r^k$ samples.\
			Figure {\ref{hist_r}} shows the distribution of the $e_{\text{clim}}$
			using all $320,000$ $r^k$ time samples.\
			The $e_{\text{AR1}}$ distribution is based on
			the collection of all $e^k$ samples generated by the 
			40 ensemble members (25 MTU each) of the AR1-process for any forecast event.\
			The $e_{\text{AR1}}$ remains informative
			since the AR1 process begins with a single true $r^k$ sample.
			A total of 300 distributions (corresponding to 300 forecast events) are constructed for $e_{\text{AR1}}$
			to check whether using the samples from the stochastic parameterization 
			and modifying them into a stationary
			distribution could achieve equivalent forecast skill. \
%			Since $e_{\text{AR1}}$ has a memory from the initial truth $r^k$, it
%			is expected to show superiority	over the uninformative $e_{\text{unif}}$.\
%			The samples of all three distributions of 
%			$e_{\text{unif}}$, $e_{\text{clim}}$, and $e_{\text{AR1}}$
%			are evaluated by the same PCE at any given lead time for the ensemble state variables.\ 
%			Three separate distributions of the forecast states 
%			will be generated accordingly.\
			
		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		\subsection{Summary of the Proposed Scheme} 
		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
			\begin{itemize}
				\item Obtain the spectral coefficients, $\hat{f}_i$, following the quadrature rule.\
				\item Construct the PCE approximation, $f(t,e_s)$, 
					of the forecast state variables $X$'s and $Y$'s.\
				\item Obtain the ensemble states of all three input distributions of 
					$e_s$ by individually sampling the PCE at the given lead times.\		
			\end{itemize}
			
			
		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		\subsection {Numerical Consistency of PCEs} \label{subsec:num_cons}	
		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
			The Root Mean Squared Difference (RMSD) is applied to measure
			the accuracy of PCE in capturing the exact model solutions.\
			The exact solutions are generated by directly integrating the 
			forecast model from a uniformly sampled $e_s$.\ 
			The same collection of samples are then evaluated by PCE.\
			The RMSD is then calculated between the exact and PCE-generated solutions.\


			Figure {\ref{rmseQpt}} shows the time series of RMSD averaged over 300 events.\ 
			It also shows how well the PCE captures 
			the exact solution as the model evolves, and how fast
			it diverges from the exact solution given different $\tau_z$.\
			The PCE deteriorates, and its corresponding RMSD grows, as bifurcations in the
                        states, amplified by nonlinear dynamics, create 
			jump discontinuities.
			These discontinuities reflect the relative predictability of the atmosphereic and oceanic component.\
			The bigger RMSD growth rate in the atmospheric component 
			is analogous to the growth rate of a realistic coupled system, where
			the atmosphere generally loses predictability faster than the ocean.\
			The atmospheric RMSD (grey) in $\tau_z=10$ (bottom) 
			saturates sooner than that in $\tau_z=2$ (top) because of 
                        % which indicates that the PCE approximation deteriorated by 
                        the increasing
			large jump discontinuities for the $\tau_z=10$ case.\
			The ocean (black) shows slower RMSD saturation because it suffers
			fewer bifurcations in the ensemble states than the atmosphere.

%			This figure is also a reference to restrict the maximum forecast lead time
%			at $5$ MTU for atmospheric component and $25$ MTU for oceanic component.\


			The qualitative differences in PCE-approximated solutions and exact solutions
			are shown in Figure {\ref{respSfc1}} ($\tau_z=2$) and Figure {\ref{respSfc2}} ($\tau_z=10$).\
			The two figures show the forecast state as a function of the 
			input perturbation $e_{\text{unif}}$ at different forecast lead times (shown above each panel)
			from the view of a single event.\
			They show how different time-scale
			of the subgrid-scale system impacts PCE approximation.\ 
			The $\tau_z=10$ case exhibits fast evolving states and multiple
			big jump discontinuities, which lead to slower convergence for the PCE,
			especially in the atmospheric component.\
			Although the ocean component 
			bifurcates multiple times in both experiments,
			the overall state spread remained in a relatively 
			narrow range (with small amplitude jumps), and
			the errors in the PCE-generated ocean ensemble remained
			small.\


			Figure {\ref{pdf1}} and Figure {\ref{pdf2}} show 
			the evolution of the state p.d.f of the exact ensemble versus PCE-generated ensemble
			\footnote{Apply kernel density estimation following {\citet{Botev10}} } 
			with respect to Figure {\ref{respSfc1}} and Figure {\ref{respSfc2}}.\
			The features of the p.d.f. shown in this event are ubiquitous in other forecast events.\
			The distributions of the atmospheric states (top panels) 
			at $\tau_z=10$ (Figure {\ref{pdf2}}) spread along 
			a wider range with larger variances
			in all lead times and constantly changing shapes (non-Gaussian).\
			Therefore the impact of input distributions of $e_s$ on the ensemble distributions
			indicate the necessity of applying informative $e_{\text{clim}}$ or $e_{\text{AR1}}$).\
			The largely bifurcated nature in $\tau_z=10$ hinders the accuracy of
			PCE on approximating the exact states at longer lead time
			(e.g., the bottom rightmost panel in Figure {\ref{pdf2}}).\
						
 

			
